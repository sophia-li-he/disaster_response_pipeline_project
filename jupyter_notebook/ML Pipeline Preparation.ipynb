{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download('punkt', 'wordnet', 'stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///message.db')\n",
    "df = pd.read_sql_table('message', engine)\n",
    "X = df['message']\n",
    "Y = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y.sum() / Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    The function normalizes the string, removes the punctuation characters, tokenizes and lemmatizes the string\n",
    "    Input: string\n",
    "    Output: clean tokens\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Case Normalization\n",
    "    text = text.lower()\n",
    "    # Remove punctuation characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    text = word_tokenize(text)\n",
    "    clean_tokens = []\n",
    "    for tok in text:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    # remove stop words\n",
    "    clean_tokens = [w for w in clean_tokens if w not in stopwords.words(\"english\")]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.65 s, sys: 1.36 s, total: 11 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "# train classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, category):\n",
    "    \"\"\"\n",
    "    input: estimator(model), testing set, testing labels, the category for the lables\n",
    "    output: \n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=category, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related      0.864     0.931     0.896       608\n",
      "               request      0.834     0.783     0.808       411\n",
      "                 offer      0.000     0.000     0.000         3\n",
      "           aid_related      0.795     0.780     0.788       423\n",
      "          medical_help      0.600     0.081     0.143        74\n",
      "      medical_products      0.750     0.176     0.286        34\n",
      "     search_and_rescue      0.000     0.000     0.000        34\n",
      "              security      0.000     0.000     0.000        13\n",
      "              military      0.000     0.000     0.000         4\n",
      "                 water      0.929     0.782     0.849       133\n",
      "                  food      0.897     0.682     0.775       192\n",
      "               shelter      0.800     0.346     0.483       104\n",
      "              clothing      0.000     0.000     0.000         7\n",
      "                 money      0.000     0.000     0.000        13\n",
      "        missing_people      0.000     0.000     0.000        14\n",
      "              refugees      0.000     0.000     0.000        20\n",
      "                 death      0.000     0.000     0.000        28\n",
      "             other_aid      0.529     0.118     0.194       152\n",
      "infrastructure_related      0.333     0.042     0.074        24\n",
      "             transport      0.000     0.000     0.000        23\n",
      "             buildings      1.000     0.140     0.245        43\n",
      "           electricity      0.000     0.000     0.000         5\n",
      "                 tools      0.000     0.000     0.000         1\n",
      "             hospitals      0.000     0.000     0.000         6\n",
      "                 shops      0.000     0.000     0.000         2\n",
      "           aid_centers      0.000     0.000     0.000         3\n",
      "  other_infrastructure      0.000     0.000     0.000        13\n",
      "       weather_related      0.860     0.327     0.474       113\n",
      "                floods      0.000     0.000     0.000        20\n",
      "                 storm      1.000     0.083     0.154        12\n",
      "                  fire      0.000     0.000     0.000         3\n",
      "            earthquake      0.881     0.561     0.685        66\n",
      "                  cold      0.000     0.000     0.000         5\n",
      "         other_weather      1.000     0.050     0.095        20\n",
      "         direct_report      0.738     0.713     0.726       380\n",
      "\n",
      "             micro avg      0.821     0.623     0.709      3006\n",
      "             macro avg      0.366     0.188     0.219      3006\n",
      "          weighted avg      0.749     0.623     0.653      3006\n",
      "           samples avg      0.682     0.550     0.564      3006\n",
      "\n",
      "CPU times: user 2.26 s, sys: 412 ms, total: 2.68 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_model(pipeline, X_test, y_test, y_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 16s, sys: 30.3 s, total: 6min 46s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "#         'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#         'features__text_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "#         'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "         'tfidf__use_idf': (True, False),\n",
    "        'clf__estimator__n_estimators': [100, 200]\n",
    "        #'clf__min_samples_split': [2, 3 , 4]\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__n_estimators': 200, 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related      0.853     0.961     0.903       608\n",
      "               request      0.832     0.830     0.831       411\n",
      "                 offer      0.000     0.000     0.000         3\n",
      "           aid_related      0.824     0.830     0.827       423\n",
      "          medical_help      0.778     0.095     0.169        74\n",
      "      medical_products      0.857     0.176     0.293        34\n",
      "     search_and_rescue      0.000     0.000     0.000        34\n",
      "              security      0.000     0.000     0.000        13\n",
      "              military      0.000     0.000     0.000         4\n",
      "                 water      0.930     0.805     0.863       133\n",
      "                  food      0.929     0.880     0.904       192\n",
      "               shelter      0.867     0.500     0.634       104\n",
      "              clothing      0.000     0.000     0.000         7\n",
      "                 money      0.000     0.000     0.000        13\n",
      "        missing_people      0.000     0.000     0.000        14\n",
      "              refugees      0.000     0.000     0.000        20\n",
      "                 death      0.000     0.000     0.000        28\n",
      "             other_aid      0.625     0.066     0.119       152\n",
      "infrastructure_related      0.000     0.000     0.000        24\n",
      "             transport      0.000     0.000     0.000        23\n",
      "             buildings      0.833     0.116     0.204        43\n",
      "           electricity      0.000     0.000     0.000         5\n",
      "                 tools      0.000     0.000     0.000         1\n",
      "             hospitals      0.000     0.000     0.000         6\n",
      "                 shops      0.000     0.000     0.000         2\n",
      "           aid_centers      0.000     0.000     0.000         3\n",
      "  other_infrastructure      0.000     0.000     0.000        13\n",
      "       weather_related      0.947     0.478     0.635       113\n",
      "                floods      0.000     0.000     0.000        20\n",
      "                 storm      1.000     0.083     0.154        12\n",
      "                  fire      0.000     0.000     0.000         3\n",
      "            earthquake      0.918     0.682     0.783        66\n",
      "                  cold      0.000     0.000     0.000         5\n",
      "         other_weather      0.000     0.000     0.000        20\n",
      "         direct_report      0.763     0.805     0.784       380\n",
      "\n",
      "             micro avg      0.840     0.678     0.750      3006\n",
      "             macro avg      0.342     0.209     0.231      3006\n",
      "          weighted avg      0.761     0.678     0.688      3006\n",
      "           samples avg      0.701     0.594     0.601      3006\n",
      "\n",
      "CPU times: user 4.71 s, sys: 444 ms, total: 5.15 s\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_model(cv, X_test, y_test, y_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 27.3 s, total: 2min 46s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use Naive Bayes algorithms\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None)))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__alpha': [0.05, 0.1],\n",
    "#         'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#         'features__text_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "#         'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "    'tfidf__use_idf': (True, False)\n",
    "        #'clf__estimator__n_estimators': [10, 50, 100] #, 200],\n",
    "        #'clf__min_samples_split': [2, 3 , 4]\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__alpha': 0.05, 'tfidf__use_idf': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related      0.864     0.964     0.911       608\n",
      "               request      0.773     0.810     0.791       411\n",
      "                 offer      0.000     0.000     0.000         3\n",
      "           aid_related      0.765     0.837     0.799       423\n",
      "          medical_help      0.600     0.041     0.076        74\n",
      "      medical_products      0.500     0.088     0.150        34\n",
      "     search_and_rescue      0.000     0.000     0.000        34\n",
      "              security      0.000     0.000     0.000        13\n",
      "              military      0.000     0.000     0.000         4\n",
      "                 water      0.786     0.496     0.608       133\n",
      "                  food      0.793     0.740     0.765       192\n",
      "               shelter      0.727     0.231     0.350       104\n",
      "              clothing      0.000     0.000     0.000         7\n",
      "                 money      0.000     0.000     0.000        13\n",
      "        missing_people      0.000     0.000     0.000        14\n",
      "              refugees      0.000     0.000     0.000        20\n",
      "                 death      1.000     0.036     0.069        28\n",
      "             other_aid      0.471     0.053     0.095       152\n",
      "infrastructure_related      0.000     0.000     0.000        24\n",
      "             transport      0.000     0.000     0.000        23\n",
      "             buildings      0.000     0.000     0.000        43\n",
      "           electricity      0.000     0.000     0.000         5\n",
      "                 tools      0.000     0.000     0.000         1\n",
      "             hospitals      0.000     0.000     0.000         6\n",
      "                 shops      0.000     0.000     0.000         2\n",
      "           aid_centers      0.000     0.000     0.000         3\n",
      "  other_infrastructure      0.000     0.000     0.000        13\n",
      "       weather_related      0.730     0.239     0.360       113\n",
      "                floods      0.000     0.000     0.000        20\n",
      "                 storm      1.000     0.083     0.154        12\n",
      "                  fire      0.000     0.000     0.000         3\n",
      "            earthquake      0.792     0.288     0.422        66\n",
      "                  cold      0.000     0.000     0.000         5\n",
      "         other_weather      0.000     0.000     0.000        20\n",
      "         direct_report      0.702     0.768     0.734       380\n",
      "\n",
      "             micro avg      0.782     0.618     0.691      3006\n",
      "             macro avg      0.300     0.162     0.180      3006\n",
      "          weighted avg      0.690     0.618     0.618      3006\n",
      "           samples avg      0.678     0.553     0.555      3006\n",
      "\n",
      "CPU times: user 2.15 s, sys: 411 ms, total: 2.56 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_model(cv, X_test, y_test, y_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 26.8 s, total: 3min 58s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use Adaboost\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=AdaBoostClassifier()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__estimator__learning_rate': [0.5, 1],\n",
    "#    'clf__estimator__alpha': [0.1, 0.5, 1]\n",
    "#         'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#         'features__text_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "#         'features__text_pipeline__vect__max_features': (None, 5000, 10000),\n",
    "    'tfidf__use_idf': (True, False)\n",
    "        #'clf__estimator__n_estimators': [10, 50, 100] #, 200],\n",
    "        #'clf__min_samples_split': [2, 3 , 4]\n",
    "    }\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__learning_rate': 0.5, 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related      0.863     0.956     0.907       608\n",
      "               request      0.845     0.781     0.812       411\n",
      "                 offer      0.000     0.000     0.000         3\n",
      "           aid_related      0.840     0.757     0.796       423\n",
      "          medical_help      0.714     0.135     0.227        74\n",
      "      medical_products      0.556     0.294     0.385        34\n",
      "     search_and_rescue      0.200     0.029     0.051        34\n",
      "              security      0.400     0.154     0.222        13\n",
      "              military      0.000     0.000     0.000         4\n",
      "                 water      0.910     0.910     0.910       133\n",
      "                  food      0.920     0.896     0.908       192\n",
      "               shelter      0.780     0.615     0.688       104\n",
      "              clothing      0.500     0.571     0.533         7\n",
      "                 money      0.444     0.308     0.364        13\n",
      "        missing_people      0.000     0.000     0.000        14\n",
      "              refugees      0.000     0.000     0.000        20\n",
      "                 death      0.833     0.179     0.294        28\n",
      "             other_aid      0.561     0.151     0.238       152\n",
      "infrastructure_related      0.000     0.000     0.000        24\n",
      "             transport      0.000     0.000     0.000        23\n",
      "             buildings      0.500     0.256     0.338        43\n",
      "           electricity      0.000     0.000     0.000         5\n",
      "                 tools      0.000     0.000     0.000         1\n",
      "             hospitals      0.000     0.000     0.000         6\n",
      "                 shops      0.000     0.000     0.000         2\n",
      "           aid_centers      0.000     0.000     0.000         3\n",
      "  other_infrastructure      0.000     0.000     0.000        13\n",
      "       weather_related      0.914     0.469     0.620       113\n",
      "                floods      0.000     0.000     0.000        20\n",
      "                 storm      0.455     0.417     0.435        12\n",
      "                  fire      1.000     0.333     0.500         3\n",
      "            earthquake      0.845     0.742     0.790        66\n",
      "                  cold      0.000     0.000     0.000         5\n",
      "         other_weather      0.000     0.000     0.000        20\n",
      "         direct_report      0.777     0.745     0.761       380\n",
      "\n",
      "             micro avg      0.814     0.679     0.740      3006\n",
      "             macro avg      0.396     0.277     0.308      3006\n",
      "          weighted avg      0.763     0.679     0.701      3006\n",
      "           samples avg      0.686     0.589     0.590      3006\n",
      "\n",
      "CPU times: user 2.76 s, sys: 472 ms, total: 3.23 s\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate_model(cv, X_test, y_test, y_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
